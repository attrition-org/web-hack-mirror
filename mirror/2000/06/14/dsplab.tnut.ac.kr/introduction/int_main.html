<HTML>
<HEAD>
   <META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=euc-kr">
   <TITLE>introduction</TITLE>
</HEAD>
<BODY TEXT="#FFFFFF" LINK="#FFFF00" VLINK="#FFFF00" BACKGROUND="../gif/back1.gif">
 <font size=7 FACE="GulimChe,돋움,Arial" COLOR="FFFFFF">
 HCI 란  무엇인가?<br><br>
 </font>  
<font size=-1 FACE="GulimChe,돋움,Arial" COLOR="FFFFFF">
&nbsp;&nbsp;인간과 컴퓨터(기계)의 관계를 어떻게 설정할 것인가 하는 문제는 컴퓨터의 등장이래 지속되온 중요한 연구 테마이다.
인간-기계 인터페이스(Human-Machine  Interface), 인간- 컴퓨터 인터페이스 (Human-Computer Interface)등으로 불리는 이들 연구는
최근까지 주로 인간의 신체적 특성과 기계 사이의 관계에 치중해 있었다. 이에 따라 연구 방향도 인간공학적 접근, 즉 테이블의
높이,의자의 높이와 폭 , 디스플레이의 위치,손잡이의 크기와 모양, 기계작동에 필요한 힘 등 기계의 사용성 향상에 초점이
맞추어져 있었다.  그러나 최근 세계 유수의 연구소들이 행하고 있는 접근 방법은 사뭇 다르다. 이들은 기계에 사람을 맞추는
것이 아니라 기계가 사람의 욕구에 맞출것을 요구한다. 다시말해 인간과 인간 사이의 의사소통 방법을 인간과 기계의 영역으로
까지 확장시키려 하고 있는것이다.<br> 
&nbsp;&nbsp;미국 카네기 멜론대학의  '오즈(OZ)프로젝트',스탠포드 대학의 '아르키메데스(Archimedes)프로젝트', 그리고 MIT미디어랩에서
추진하고 있는 '생각하는 사물(Things That Think)등으로 대표되는 새로운 인터페이스 연구는 오늘날의 개인용 컴퓨터가
'개인용'이란 이름에 걸맞는 제 역할을 못하고 있다는 현실 인식에서 출발한다.<br> 
&nbsp;&nbsp;  우리의 책상 한 부분을 차지하고 있는 컴퓨터는 '나만의 것'이다. 그러나 이 기계가 '나를위해' 하는 일이라곤 매우 제한적이다.
심하게 말하자면 하루  중 책상에 앉아 있는 시간을 제외하고 컴퓨터는 나를 위해 '아무 일도 하지 않는다'. 물론 노트북 컴퓨터가
등장하면서 공간적 한계는 많이 극복됐다고 하지만, 여전히 작업 내용을 보기위해서는 모니터를 켜야하고, 자료를 입력하기
위해서는 손가락으로 키보드와 마우스를 조작해야 한다. 그러나 새로운 인터페이스의 컴퓨터는 CPU와 모니터, 키보드에
얽매인 '컴퓨터 신화'를 깰 것을 요구한다. 연구자들에게 컴퓨터란 안경처럼 코에 걸치거나 옷처럼 입을수 있으며, 상황에 맞추어 개인과
'대화'를 나눌 수 있는 친절한 기계다. 카네기 멜론대학의 OZ프로젝트는 인간과 상호작용하는 '컴퓨터인물'을 개발하려는 계획이다.
이 컴퓨터 인물은 감정을 가지고 있어 사람이 부드럽게 이야기하면 밝은 표정을 짓고, 험악한 말투에는 겁먹은 표정과 함께 움추려드는 
행동을 보여준다. 또 다른 컴퓨터 인물들과 상호작용을 하면 주어진 공간내에서 변화하기도 한다. 스탠포드 대학의 아르키메데스 프로젝트는
장애인을 위한 컴퓨터의 개발에 초점을 맞추고 있다. 여기서 강조되는 부분은 언어를 이용한 컴퓨터 조작이다. 목 아래전신이 마비된
대학원생이 머리를 움직여 컴퓨터의 커서를 이동시키고, 말로 컴퓨터를 조작해 논문을 쓰고 전자우편을 보낸다. 불완전한 문장을 인식하는
기술, 눈동자 움직임을 추적해 컴퓨터의 커서를 이동시키는 기술을 이용하면 언어를 제대로 구사하지 못하는 언어장애자도 컴퓨터를
자유자재로 활용할 수 있다.<br> 
&nbsp;&nbsp;  아르키메데스 프로젝트에서는 컴퓨터 사용자와 컴퓨터의 성격을 일치시켜 업무 효과와 사용만족성을 높이려는 시도도 이루어지고 있다.
사람들은 자신과 비슷한 성격의 사람과 잘 어울린다는 사회심리학적 사실을 바탕에 둔 이연구는 개인의 성격을 공격적인 성격과 부드러운
성격 등으로 분포하고 컴퓨터도 사용자의 성격에 따라 동일하게 반응하도록 했다. 이 연구의 일부는 마이크로 소프트사의 컴퓨터 운영시스템
'밥'(Bob)에 활용됐으나 일반인들의 관심을 끌지는 못했다. 그러나 앞으로 컴퓨터가 진정한 의미의 개인화를 이루고, 컴퓨터와 사용자
사이의 대화가 이루어진다면 연구의 결과는 중요하게 활용될 것이다. 
</font><br><br>
<font size=7 FACE="GulimChe,돋움,Arial" COLOR="FFFFFF">
 음성인식에 대한 소개<br><br>
</font>
<font size=-1 FACE="GulimChe,돋움,Arial" COLOR="FFFFFF">
&nbsp;&nbsp;1. 음성이란<br><br>
&nbsp;&nbsp;음성은 인간이 가지고 있는 기본적인 능력	중에서 가장 중요한 것 중 하나로서 우리가 속박감을 
거의 느끼지 않고 자유롭게 구사할 수 있는 가장 자연스럽고 효과적인 정보교류의 수단이라 
말 할 수 있다. 또 음성에 의해 표현되는 말은 인간과 인간사이의 의사소통의 수단으로서 뿐만 
아니라 논리적으로 사물을 생각하는 경우에 있어서도 중요한 역할을 한다. 이 음성이 인간과 
기계와의 통신, 즉, 정보의 교환수단으로도 사용되어 오고 있다.<br><br>
&nbsp;&nbsp;최근 음성과 자연언어의 기본적인 성질의 이해에 관한 관심도 높아지고 있고 각종 미디어의 발달, 
초고속 정보 통신망의 구축과 더불어 멀티미디어 통신을 통한 통신 판매, 물류처리, 제품홍보 등이
폭증하고 있으며 지방자치 시대의 도래와 더불어 관공서의 대민 서비스의 질에 관한 관심도 점점 
높아져가고 있다. 이와 더불어 개인용 컴퓨터의 보급에 의한 신호처리기술과 정보처리기술의 
급속한 발전과 더불어 음성을 통한 인간과 기계와의 직접적인 커뮤니케이션을 위한 Man-Machine 
Interface의 중요성도 강조되고 있다. 또 인간과 기계사이 뿐만 아니라 인간과 인간사이에 기계를
넣어 통역을 자동적으로 하고자 하는 연구도 활발히 진해되고 있다.<br><br>
&nbsp;&nbsp;1960년대부터 음성의 발성과 이해에 관해 많은 기초적 연구가 수행되어온 이래 기계에 의한 
연속음성인식, 합성에는 아직 많은 과제가 남아있지만 최근 30-40 여년간 연구결과로 고립단어 인식에
있어서는 많은 발전이 있어 미국, 유럽, 일본 등에서는 상용제품도 출현하고 있다. 이들 인식시스템의 
대부분은 고립단어, 또는 한정된 태스크 범주의 연속음성인식시스템이지만 잡음환경 하에서도 
95%이상의 인식률을 가진 것이 많다. 인식시스템의 경우, 성능이 향상하는 것에 비례하여 응용분야
도 복잡화 다양화되어가고 있다. 예를 들면 각종 자료의 수정 및 관리, 철도 또는 항공편 안내 및
예약, Dictati System, 통역전화, 자동통역시스템, 여행정보안내 시스템, 관광안내 시스템 등을 
개발하여 상품화하고 있으며 국내에서도 음성구동 퍼스널 컴퓨터, 증권정보안내 시스템이 개발되어 
상용화가 진행 중에 있고, 미국, 일본 등과 나란히 자동통역시스템 개발사업에도 참여하고 있다.
또 음성 다이얼링 휴대폰도 개발되어 이용되어 있는 등 그 응용 범위는 광범하다.<br><br>

2. 음성인식 발달사<br><br>

2.1 DTW와 HMM<br><br>
&nbsp;&nbsp;1970년대  초에 일본에 있어서의 중요한 연구성과의 하나로 Sokoe에 의한 동적계획법(Dynamic 
Programming : DP)을 이용한 시간축 정합법(미국 : Dynamic Time Warping : DTW, 일본 
DP matching법)이 있다. 이것은 음성의 시간축의 신축에 대처하면서 2개의 패턴의 유사도(거리)를
계산하는 극히 효율적인 방법이다.  이때에 소련(현 우크라이나)에도 연구되고 있었다는 것이 
후에 알려졌다. 이와같이 음성의 시간신축의 정규화에 동적계획법을 이용하는 방법은 2단 
DTW(2 Level DTW)법 또는 그 변형으로서 연속단어 음성인식에 대한 단어열의 정합에도 이용되었
으며 현재의 HMM에 의한 음성인식에도  이용되고 있다.<br><br>
&nbsp;&nbsp;1980년대는 이때까지의 음성의 시간패턴을 직접정합(Matching)시키는 방법으로부터 HMM을 대표로 
하는 통계적 모델화에 기초를 둔 방법으로의 이행으로 특징되어 질 수 있다. HMM에 의한 방법은 
IBM,CMU등의 소수의 연구소에서는 그 이전부터 잘 알려져 있지만 일반에게는 1980연대 중반경에 
그 구체적인 방법과 이론이 Bell 연구소 연구자들에 의해 널리 발표되어 처음으로 세계의 여러 
연구기관에서 이용되고 있다.<br><br>

2.2 Neural Network<br><br>
&nbsp;&nbsp;1980연대의 신경망 붐이 한창일 때 음성인식분야에서도 신경망을 이용하는 시도가 많이 이루어져 
한정된 테스크에 있어서는 높은 인식성능을 나타내어 주목을 받은 때가 있다. 그러나, 결국 HMM과
같은 통계적 방법을 명확히 능가하지는 못하고 있다. 또, 연속음성인식과 같은 음향모델과 
언어모델을 복잡하게 조합하지 않으면 안되는 경우에서는 비선형적인 처리결과를 종합적인 스코어
로 축적한다든지 하여 문장 전체로서의 인식성능을 높이는 파라미터의 최적화를 꾀하는 것이 매우
힘들기 때문에 최근 음성인식에 있어서의 신경망에 과한 연구는 열기가 식어가고 있다.<br><br>
&nbsp;&nbsp;그러나 신경망의 일종인 학습벡터 양자화(LVQ : Learning Vector Quantization)의 이론적 발전과
더불어 파생된 오인식 별소화 학습법(MCE/GDP)은 차후 학습법의 하나로 현재 주목되고 있다.<br><br>

3. 음성인식 기술<br><br>
3.1 음성인식 기술 개요<br><br>
&nbsp;&nbsp;음성인식에 관한 연구는 약 40여 년간의 역사를 가지고 있으며 그 동안 많은 변화를 거듭해 왔다. 
현재까지 개발된 여러 가지 음성인식 수법 중 선형예측분석법(Linea Predictive Analysis),
 ΔCepstrum, DP(Dyn Programming), HMM(Hidden Markov Model), 통계적 언어 모델 등의 기술은 
통계적 처리가 중심이 되고 있는 최근의 음성인식 기술의 흐름 속에서 계속 살아 남아있지만 
과거에 활발하게 연구된 기술 중에는 통계적 처리에 잘 맞지 않는다든지 하여 존재의미를 
잃어버린 기술도 많다. 음성인식기술은 아직 해결하지 않으면 안 되는 과제도 많지만 금후 
Multimedia 환경 구축에도 여러 형태로 사용될 것으로 기대된다.<br><br>

3.2 현재의 음성인식 기술<br><br>
&nbsp;&nbsp;현재의 음성인식 시스템의 전형적 구성형태를 그림1에서 보인다. 대어휘 연속음성인식에서 
Bottom-up 처리를 하면 인식결과의 후보의 수가 폭발적으로 증가해 버린다. 이 때문에 인식대상 
태스크에 적합한 언어모델(단어 사전, 의미정보, 구문정보, 문맥 정보 등)을 Top-down법을 
이용하여 문장가설을 생성(예측)하여 그것을 음소계열로 나타낸 것을 순서대로 입력음성과 
조합하여 검증해 가는 방법을 취한다.<br><br>
&nbsp;&nbsp;입력음성은 음소 조합 전에 5-10ms 마다 Spectra Parameter Vector로 변환하여 두는데 현재까지 
개발된 거의 모든 시스템에서 켑스트럼과 그 시간적 변화의 미분계수인 Δ켑스트럼이 사용되고 
있으며 인식의 기본단위인 음소의 음향모델로서는 HMM을 사용하고 있다. 단어사전은 단어의 
발성을 음소모델의 계열로 나타내는 것인데 조음결합 때문에 각 음소의 발음은 전후 음소의 
영향을 받아 변형된다. 이 때문에 각 음소별로 전후 음소에 의존한 복수의 음소환경의조모델을 
이용한다.<br><br> 
&nbsp;&nbsp;언어모델로서는 여러 가지 방법이 연구되고 있으나 가장 많이 이용되고 있는 것으로는 통계적 
언어모델이다. 구체적으로는 Bigram, Trigram 등 단어의 연쇄확률이 이용된다. 그 밖의 
언어모델로서는 문맥자유문법, 유한상태 네트워크 문법 등이 이용되고 있다. 이때 모든 음향적 
언어적 제약을 만족하는 가장 가능성이 높은 문장을 탐색하는 알고리즘에 관한 연구도 매우 
중요한데 프레임 동기형 빔 탐색, A*탐색 등이 이용되고 있다.<br><br>
&nbsp;&nbsp;복수의 지식원을 통합하는 방법으로서 N-best 탐색법도 이상적 방법의 하나로서 널리 이용되고 
있다. 이것은 우선 간단한 음향모델과 언어모델을 이용해서 N개까지의 인식결과후보를 선택한 
후 다음 정도가 높은 모델을 이용해 이들 후보의 순위를 재평가함으로 인식성능을 향상시키는 
방법이다.<br><br>

4. 음성인식 연구의 국내외 현황<br><br>
4.1 국외 현황<br><br>
&nbsp;&nbsp;미국의 경우 1970년부터 미 국방성의 주도에 의한 ARPA 프로젝트의 일환으로 연속음성인식에 
대한 본 격적인 연구가 시작되어 진행되던 중 1984년부터 DARPA 프로젝트로 바뀌어 대용량 어휘 
음성인식 및 구어체 언어 이해 연구가 진행되었다. 이 연구의 장기적인 목표는 100,000 단어의 
어휘를 대상으로 한 연속 음성인식이며 단기적으로는 10,000 단어의 어휘를 사용하여 연속음성을 
인식하되 95% 이상의 단어 인식률을 얻는 것을 목표로 하고 있다. 이 계획에는 미국 주요 대학 
및 연구기관이 참여하여 낭독체의 자원 관리에 의한 질의 및 명령어나 자연스런 대화체의 항공 
여행 정보 안내에 의한 질의 및 성능 평가를 통해 경쟁적인 기술 개발을 유도해 
가고 있다.<br><br>
&nbsp;&nbsp;또한 음성인식과 더불어 터치스크린, 제스처, 문자인식, 얼굴표정, 눈동자의 움직임 등의 
비음성 의사표현 수단을 이용한 멀티미디어 에이전트에 관한 연구도 활발하게 이루어지고 있다. 
최근의 DARPA프로젝트 는 방송 뉴스 연속음성인식 코퍼스인 Hub4를 대상으로 연구가 진행되고 
있다. BBN에서는 BYBLOS시스 템을 이용하여 발음 변화, 액센트, 상호조음과 발성 모드에 따른 
자연 발화 음성인식의 인식 성능을 개선 하여 Hub4 96데이터에 대하여 인식실험을 실시한 결과
84.1%의 단어인식률을 얻는다. 또 GTN웹사이트 와 음성언어 대화 인터페이스를 이용하여 전화를 
통하여 정보를 획득할 수 있는 GTNPhone을 개발하였 는데, 이것은 무선, 유선 전화를 사용하여 
정보를 검색할 수 있다. Cambridge 대학에서는 HMM과  MLP (Multilayer Perceptron) 기반의 
ABBOT 시스템을 개발하여 1997년 DARPA Hub4 데이터를 대상으로 한 인식 실험에서 72.9%의 
단어인식률을 얻었다. Dragon사는 Hub4에 맞게 Dragon 시스템을 수정하여 성별 독립, 
화자 정규화 모델을 사용하여 적응화 뒤 인식률은 78.6%의 단어인식률을 얻었다. SRI에서는
GMS (Gaussian Merging splitting)알고리즘으로 학습하여 WSJ94S0중 209문장을 대상으로 
인식실험을 수행한 결과 88.3%의 인식률을 얻었다.<br><br> 
&nbsp;&nbsp;한편, 일본의 NTT에서는 일본어 방송 뉴스를 대상으로 80.7%의 단어인식률을 얻었다. 
이외에 CMU 에 서는 MS-TDNN(Multi-State Time Delay Neural Network) 기반의 전화 코퍼스를 
인식대상으로 하는 시스템을 구축하여 305개의 전화를 통해 녹음한 사람 이름에 대하여 평균 
97.7%의 인식률을 보였다. 그리고 최근 JRTK(Janus Recognition ToolKit)을 사용하여 회의 
대화를 인식의 태스크로 하는 Meeting Browser Interface 시스템을 개발하여 3명의 참가자가 
회의 대화를 핀 마이크를 통하여 발성된 음성을 대상으로 테스트를 실시한 결과 적응화 후 
57.2%의 저조한 인식률을 얻었다. 이것은 입력되는 음성이 단일지향성이 아닌 무지향성 
마이크로 채록되기 때문에 채널왜곡이 심하고 실제 회의 대화를 대상으로 한 데이터를 
이용하였기 때문이다.<br><br>
또한 음성인식기능을 보완하기 위한 방법으로 오인식을 대상으로 하는 멀티모달 접근법을 
도입하였다. 멀티모드로서는 단어 및 철자의 재발성, 필시 등을 이용하였는데, 입력 희망 
양식을 태스크로 한 실험에서 단어 인식률이 78%인 경우 재 수정방법으로 철자 재발성을 이용한 
경우가 93%로 가장 높았다.<br><br>
&nbsp;&nbsp;Texas Instruments에서는 여러 가지 다양한 연구가 진행되고 있다. 영어뿐만 아니라 다른 언어를
대상으 로 확장하여, 일본어를 사용하여 WWW 브라우저를 제어하는 
&nbsp;&nbsp;SAM(Speech - Aware Multimedia)을 개발 하여 평균 91.5%의 문장인식률을 얻었다.<br><br> 
또한 전화채널을 통한 10연속 전화번호 인식에서 화자적응화 후 99.0%의 단어인식률과 94.3%의 
문장인식률을 보였다.<br><br>
&nbsp;&nbsp;BBN Systems and Technologies에서는 WSJ(Wall Stree Journal) 코퍼스 중 20명의 화자에 대하여 
SAT (Speake Adaptive Training)을 이용한 인식실험 결과 적응화 93.53%, 적응화 후 95.18%의 
단어인식률을 나타내었다. 또, 연속음성의 효과적 인식을 위해 의미론적 파싱, 의미론적 분류, 
화법 모델링의 세단계를 거쳐 ARPA Air Travel Information System (ATIS) 태스크에 대하여 시험 결과 90.3%의 문장인식률을 얻었다.
Bell 연구소에서는 inter-word 문맥종속 모델을 MCE(Minimum Classification Error)학습을 
사용하여 2,986전화번호를 대상으로 하는 화적독립 인식실험을 수행하여 90.9%의 인식률을 
얻었다.<br><br>
&nbsp;&nbsp;MIT에서는 GALAXY 시스템에 기반한 전자적 자동차 분류 광고 데이터베이스에 접근하여 정보를 
제공해 주는 대화 시스템인 WHEEL을 개발하여 5,000 종류의 자동차의 데이터베이스를 검색하기 
위한 1,200개 의 발성을 대상으로 한 성능평가 결과 76.3%의 인식률을 얻었다. 역시 GALAXY에 
기반한 식당 안내 시 스템인 DINEX를 개발하여 보스턴 시내 450개의 식당을 대상으로 하여 
실험한 결과 약 72%의 인식률을 얻었다.<br><br>
&nbsp;&nbsp;일본의 경우 1986년이래 15년간의 장기 계획으로 자동통역전화개발을 추진해 오고 있으며, 
1987년에는 국가 주도에 의한 인간과 기계화의 구어체대화를 목표로하는 "Advanced Man-Machine 
Interface Throu gh spoken Language" 계획이 시작되어 대화체 언어이해 및 소음환경에서의 
음성인식에 관한 연구가 진 행되어 많은 결과를 도출하였다. NTT에서는 음성에 의한 홈뱅킹 
시스템을 개발하여 전화를 통하여 7연속 숫자, 은행 이름, 돈 액수 등을 대상으로 하여 약 
85%의 인식률을 얻었다. 동경공대에서는 문맥종속 음소 모델과 단어 trigram을 이용한 대어휘
연속음성인식 시스템을 개발하여 10명의 화자가 발성한 일본어 경제신문 내용을 대상으로 인식 
실험을 수행하였다. 언어의 복잡도가 평균 72인 경우 평균89.9%의 문장 인식률을 
나타내었다. <br><br>
&nbsp;&nbsp;이외에 음성인식 기술을 응용한 시스템으로서는 토요하시 과학기술대학의 관광안내 시스템, 
TOSHIBA의 음성인식 자동판매기, NTT의 주소입력시스템, 
ATR(ATR Interpreting Telecommunications Research Laboratory 성번역통신 연구소의 ASURA 
등이 있다.<br><br>

&nbsp;&nbsp;유럽의 경우 1983년부터 ESPRIT 프로젝트를 중심으로 하여 현재까지 약 40여개의 프로젝트를 
수행하고 있으며, 최근에는 대화체 음성인식과 사외적 요구에 중삼을둔 새로운 프로젝트들이 
진행중에 있다. 대표 적인 연구로서는 조음처리에서 조음적-음향학적 상관관계, 화자특성의 
분석과 합성 등에 대한 기본적인 연구와 더불어 음성처리를 위한 보다 향상된 알고리즘과 
구조에 관한 연구, 음성의 지능적이고 지식적 인식, Hybrid 시스템을 위한 음성인식 알고리즘, 
다중 언어 음성입-출력, Human-machine인터페이스에서 음성의 효과적 이용을 위한 연구, 
유럽 언어들의 언어학적 분석, 다중 언어 음성-텍스트와 텍스트-음성 변환 시스템, 대화 
시스템 등 광범위한 연구가 진행되고 있다.<br><br>
이 중에서도 프랑스의 LIMSI 시스템은 연속 혼합 밀도, tied-state cross-word 문맥 의존 
HMM을 이용하 Hub4E 데이터에 대해 단어인식률 81.5%를 얻고 있다. 그리고 미국의 Texas 
Instruments와 함께 연속 음성인식시스템을 구성하여 241문장, 복잡도가 31인 태스크를 
대상으로 평균 99.31% 단어인식률을 얻었다.<br><br>
&nbsp;&nbsp;독일에서는 Grrman VERBOBILE 프로젝트(영역 : 약속 스케쥴)에서 구문론적, 운율적 경계에 
대한 레이 블링을 도입하여 122개의 문장에 대하여 96%이상의 단어인식률을 달성하였다.<br><br>


4.2 국내현황<br><br>
&nbsp;&nbsp;국내에서도 1980년도에 들면서부터 본격적인 음성인식에 관한 연구가 이루어져 오고 있다. 
개발된 시스 템으로는 한국전자통신 연구소의 자동통역시스템, 한국통신의 증권정보 안내시스템,
삼성전자의 음성구 동 퍼스널 컴퓨터, 음성구동 셀룰러폰(삼성, LG), 음성메모장치(공성 통신)
등이 있으며 현재 성능개선 또 는 상용화 중에 있다. 또 음성에 의한 로봇 제어에 관한 연구, 
음성에 의한 자동항법 장치 등에 관한 연구 도 활발히 진행되고 있다. 이하 몇몇 연구기관들의 
연구 예를 구체적으로 나열하기로 한다.<br><br>
한국과학기술원 음성언어연구실에서는 Triphone 모델을 인식 단위로 한 화자독립 연속음성인식
에서 3,0 00단어 규모의 연속음성인식 시스템을 개발하여 단어인식률 92.19%, 문장인식률 67.8%
를 달성하고 있다.<br><br>
한국전자통신연구원에는 1995년부터 Human-Computer Interface를 위한 음성 입/출력 처리에 
관한 연 구로 5,500 단어 규모의 연속음성 번역 시스템(한국어-영어, 한국어-일어)을 개발하고 
있으며, 현재 한- 영 번역 시스템에서 평균 79.1%의 변환율을 얻고 있다. 그리고, 멀티모달 
휴먼인터페이스에 관한 연구도 진행되고 있다.<br><br>
한국통신에서는 증권정보 안내시스템과 함께 호텔예약 테스크에 대한 번역시스템을 개발하여 
총 30,204 어절을 대상으로 한 실험에서 92.3%의 변환률을 얻고 있으며 성능개선을 거듭하고 
있다.<br><br>

5. 음성인식 기술의 21세기의 전망<br><br>
&nbsp;&nbsp;최근 음성인식기술은 미국을 중심으로 구체적인 응용분야가 개척되어오고 있고 멀티모드
/멀티미디어 환경 속에서의 다른 미디어와 통합에 관한 연구가 진행되고 있다. 향후 이러한 
멀티미디어와 결합되는 연구가 더욱 활발하게 진행될 것으로 기대된다. 이러한 멀티모드/ 
멀티미디어 기술의 활용분야로는 각종 멀티미디어 정보기기의 입출력 인터페이스, 카네비게이션 
시스템 개발, 시각 장애자를 위한 서비스 시스템, 대화형 자판기, 대화형 Robot, 3차 컴퓨터
시스템 개발, 제품의 검사, 멀티모드 의료 서비스, 각종 멀티모달 데이터 베이스 검색 
멀티모드형 인터넷 검색기, 홈쇼핑, 자동 예약/문의 시스템, 음성 입출력 PC, 전자 메일 
시스템 개발, 멀티모드형 자동항법 장치 개발, KIOSK 개발 등 그 분야는 이루 헤아릴 수 없다. 
이와 같은 응용연구와 더불어 자연어 처리기술을 적극적으로 이용하는 자연발화 대화체 연속음성 
인식에 관한 연구가 더욱 활발하게 진행될 것 생각된다. 이와 더불어 각국간의 자동통역전화에 
관한 연구 도 가속화될 것으로 보인다.<br><br>
&nbsp;&nbsp;음성인식 전반적으로서는 현재의 통계적 방법을 기반으로 실재의 대량의 음성 데이터의 
음성 데이터에 기초를 둔 일상 언어의 언어모델을 구축하는 것, 다수화자의 음성데이터에 
기저하여 개인차의 모델을 구출하여 이에 의한 다수 화자의 음성에의 적응화 알고리즘에 
개발하는 것, 여러 종류의 잡음, 왜곡에 자동적으로 적응되는 방법을 확립하는 것 등이 
중요한 기술적 과제로 될 것이다.<br><br>
&nbsp;&nbsp;국내적으로는 하루빨리 대규모 한국어 음성데이터베이스가 구축되어 많은 음성연구자들이 
공동으로 이용하여 서로의 연구결과를 평가하고 그 결과를 공유할 수 있는 기반이 조성되어야 
할 것으로 생각된다.<br><br>
 
</font>   
</body>
</html>

